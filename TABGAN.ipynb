{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0joqdbKedFtm"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_5_tabular_synthetic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or3fhGk9dFtn"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "**Module 7: Generative Adversarial Networks**\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-QArqZxdFto"
      },
      "source": [
        "# Module 7 Material\n",
        "\n",
        "* Part 7.1: Introduction to GANs for Image and Data Generation [[Video]](https://www.youtube.com/watch?v=hZw-AjbdN5k&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_1_gan_intro.ipynb)\n",
        "* Part 7.2: Train StyleGAN3 with your Own Images [[Video]](https://www.youtube.com/watch?v=R546LYsQk5M&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_2_train_gan.ipynb)\n",
        "* Part 7.3: Exploring the StyleGAN Latent Vector [[Video]](https://www.youtube.com/watch?v=goQzp8QSb2s&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_3_latent_vector.ipynb)\n",
        "* Part 7.4: GANs to Enhance Old Photographs Deoldify [[Video]](https://www.youtube.com/watch?v=0OTd5GlHRx4&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_4_deoldify.ipynb)\n",
        "* **Part 7.5: GANs for Tabular Synthetic Data Generation** [[Video]](https://www.youtube.com/watch?v=yujdA46HKwA&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_5_tabular_synthetic.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn-FViihdN1M"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n",
        "  Running the following code will map your GDrive to ```/content/drive```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7G_GEwHdOrE"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCb4iUtAdFto"
      },
      "source": [
        "# Part 7.5: GANs for Tabular Synthetic Data Generation\n",
        "\n",
        "Typically GANs are used to generate images. However, we can also generate tabular data from a GAN. In this part, we will use the Python tabgan utility to create fake data from tabular data. Specifically, we will use the Auto MPG dataset to train a GAN to generate fake cars.  [Cite:ashrapov2020tabular](https://arxiv.org/pdf/2010.00638.pdf)\n",
        "\n",
        "## Installing Tabgan\n",
        "\n",
        "Pytorch is the foundation of the tabgan neural network utility. The following code installs the needed software to run tabgan in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-iTPkSWdsGa"
      },
      "outputs": [],
      "source": [
        "# HIDE OUTPUT\n",
        "CMD = \"wget https://raw.githubusercontent.com/Diyago/\"\\\n",
        "  \"GAN-for-tabular-data/master/requirements.txt\"\n",
        "\n",
        "!{CMD}\n",
        "!pip install -r requirements.txt\n",
        "!pip install tabgan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlETatByeGqz"
      },
      "source": [
        "Note, after installing; you may see this message:\n",
        "\n",
        "* You must restart the runtime in order to use newly installed versions.\n",
        "\n",
        "If so, click the \"restart runtime\" button just under the message. Then rerun this notebook, and you should not receive further issues.\n",
        "\n",
        "## Loading the Auto MPG Data and Training a Neural Network\n",
        "\n",
        "We will begin by generating fake data for the Auto MPG dataset we have previously seen. The tabgan library can generate categorical (textual) and continuous (numeric) data. However, it cannot generate unstructured data, such as the name of the automobile. Car names, such as \"AMC Rebel SST\" cannot be replicated by the GAN, because every row has a different car name; it is a textual but non-categorical value.\n",
        "\n",
        "The following code is similar to what we have seen before. We load the AutoMPG dataset. The tabgan library requires Pandas dataframe to train. Because of this, we keep both the Pandas and Numpy values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-EZEaj-wNT5"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YRAjvvMeWuz"
      },
      "outputs": [],
      "source": [
        "# HIDE OUTPUT\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "df = pd.read_csv(\"/content/small_scale_50percent_combined_genecounts.csv\")\n",
        "\n",
        "COLS_USED = ['GeneIDs','CLL Gene Counts (SRR1812702)','CLL Gene Counts (SRR1812703)',\n",
        "             'CLL Gene Counts (SRR1812704)','CLL Gene Counts (SRR1812705)',\n",
        "             'CLL Gene Counts (SRR1812706)','CLL Gene Counts (SRR13310942)',\n",
        "             'CLL Gene Counts (SRR13310943)','CLL Gene Counts (SRR13310944)',\n",
        "             'CLL Gene Counts (SRR13310945)','CLL Gene Counts (SRR13310946)','CLL Gene Counts (SRR13310947)',\n",
        "             'Non-CLL Gene Counts (SRR1812751)','Non-CLL Gene Counts (SRR1812752)','Non-CLL Gene Counts (SRR1812753)']\n",
        "\n",
        "df = df[COLS_USED]\n",
        "\n",
        "\n",
        "# Split into training and test sets\n",
        "df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(\n",
        "    df_train.drop(['GeneIDs','CLL Gene Counts (SRR1812702)'],axis=1),\n",
        "    df_train['CLL Gene Counts (SRR1812702)'],\n",
        "    test_size=0.10,\n",
        "    shuffle=False,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# Create dataframe versions for tabular GAN\n",
        "df_x_test, df_y_test = df_x_test.reset_index(drop=True), \\\n",
        "df_y_test.reset_index(drop=True)\n",
        "df_y_train = pd.DataFrame(df_y_train)\n",
        "df_y_test = pd.DataFrame(df_y_test)\n",
        "\n",
        "# Pandas to Numpy\n",
        "x_train = df_x_train.to_numpy()\n",
        "y_train = df_y_train.to_numpy()\n",
        "x_test = df_x_test.to_numpy()\n",
        "y_test = df_y_test.to_numpy()\n",
        "\n",
        "\n",
        "# Build the neural network\n",
        "model = Sequential([\n",
        "    Dense(200, input_dim=x_train.shape[1], activation='relu'),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(12, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1,\n",
        "     patience=5, verbose=2, mode='auto',\n",
        "       restore_best_weights=True)\n",
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],\n",
        "         verbose=2,epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeR9CQ5weQDB"
      },
      "source": [
        "We now evaluate the trained neural network to see the RMSE. We will use this trained neural network to compare the accuracy between the original data and the GAN-generated data. We will later see that you can use such comparisons for anomaly detection. We can use this technique can be used for security systems. If a neural network trained on original data does not perform well on new data, then the new data may be suspect or fake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFijxBaufVzr"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(x_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
        "print(\"Final score (RMSE): {}\".format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k33foL3eTDN"
      },
      "source": [
        "## Training a GAN for Auto MPG\n",
        "\n",
        "Next, we will train the GAN to generate fake data from the original MPG data. There are quite a few options that you can fine-tune for the GAN. The example presented here uses most of the default values. These are the usual hyperparameters that must be tuned for any model and require some experimentation for optimal results. To learn more about tabgab refer to its paper or this [Medium article](https://towardsdatascience.com/review-of-gans-for-tabular-data-a30a2199342), written by the creator of tabgan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-i4CdwYkgLU"
      },
      "outputs": [],
      "source": [
        "from tabgan.sampler import GANGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "gen_x, gen_y = GANGenerator(gen_x_times=15, cat_cols=None,\n",
        "           bot_filter_quantile=0.001, top_filter_quantile=0.999,\n",
        "           is_post_process=True,\n",
        "           adversarial_model_params={\n",
        "               \"metrics\": \"rmse\",\n",
        "               \"max_depth\": 2,\n",
        "               \"max_bin\": 5500,\n",
        "               \"learning_rate\": 0.001,\n",
        "               \"random_state\": 42,\n",
        "               \"n_estimators\": 300,\n",
        "               \"force_col_wise\": True,\n",
        "               # Added here if LightGBM accepts it through GANGenerator\n",
        "           },\n",
        "           pregeneration_frac=2,\n",
        "           only_generated_data=False,\n",
        "          ).generate_data_pipe(df_x_train, df_y_train, df_x_test, deep_copy=True,\n",
        "                               only_adversarial=False, use_adversarial=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBxYegwNdXdz"
      },
      "source": [
        "Note: if you receive an error running the above code, you likely need to restart the runtime. You should have a \"restart runtime\" button in the output from the second cell. Once you restart the runtime, rerun all of the cells. This step is necessary as tabgan requires specific versions of some packages.\n",
        "\n",
        "## Evaluating the GAN Results\n",
        "\n",
        "If we display the results, we can see that the GAN-generated data looks similar to the original. Some values, typically whole numbers in the original data, have fractional values in the synthetic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzKROV-Pm1SE"
      },
      "outputs": [],
      "source": [
        "gen_x_new =gen_x.astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPZwlYt42GFD"
      },
      "outputs": [],
      "source": [
        "# Assuming df is your DataFrame\n",
        "gen_x.to_csv('synthetic_10CLL_20percent_smallscale_genecounts.csv', index=False)  # Save DataFrame to CSV\n",
        "\n",
        "from google.colab import files\n",
        "files.download('synthetic_10CLL_20percent_smallscale_genecounts.csv')  # Download the file to your local system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ6lc2EHn8i5"
      },
      "source": [
        "Finally, we present the synthetic data to the previously trained neural network to see how accurately we can predict the synthetic targets.  As we can see, you lose some RMSE accuracy by going to synthetic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXoMORyHCU0o"
      },
      "outputs": [],
      "source": [
        "# Predict\n",
        "pred = model.predict(gen_x_new.values)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,gen_y.values))\n",
        "print(\"Final score (RMSE): {}\".format(score))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Assume x_train is your real data and gen_x is your generated data\n",
        "real_labels = np.ones(len(x_train_new))  # Labels for real data\n",
        "generated_labels = np.zeros(len(gen_x_new))  # Labels for generated data\n",
        "\n",
        "# Combine the real and generated data\n",
        "combined_samples = np.vstack((x_train_new, gen_x_new))\n",
        "combined_labels = np.hstack((real_labels, generated_labels))\n",
        "\n",
        "# Shuffle the combined dataset to ensure random distribution\n",
        "shuffled_indices = np.random.permutation(len(combined_samples))\n",
        "combined_samples = combined_samples[shuffled_indices]\n",
        "combined_labels = combined_labels[shuffled_indices]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_samples, combined_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a classifier to distinguish between real and generated data\n",
        "classifier = RandomForestClassifier(random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qd-luJ2c1Mu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "auc_roc = roc_auc_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"AUC-ROC: {auc_roc}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "RSADF88Bujk6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}